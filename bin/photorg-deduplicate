#!/usr/bin/python

"""
Find all duplicate files. Files are traversed in the order specified.
By default it will only list duplicates.
    
    --delete : DELETE ALL except the first occurance of duplicate files 
    --move : Move dupliates into specified directory
    --hardlink : Replace duplicates with hardlink to first occurance

To keep orginals in named directories and remove from everything else use bash globbing:
    https://www.gnu.org/software/bash/manual/bashref.html#Pattern-Matching
    photorg-deduplicate 2015-07-??_* 2015-07-?? 

To scan a directory on a remote server and delete local files which are also on server:

    ssh user@myserver find ~/photos -type f -exec 'sha1sum {} \;' > server_photo_sha1sums.txt
    photorg-deduplicate --from-file server_photo_sha1sums.txt ~/local_photos --delete

"""

import argparse
from photorg import *


if __name__=='__main__':
    parser = argparse.ArgumentParser(description=__doc__.strip())
    parser.add_argument('directories', metavar='DIR', nargs='+', help='Directories to scan for duplicates')
    parser.add_argument('--delete', action='store_true', help='delete ALL except first occurance of duplicate files')
    #parser.add_argument('--hardlink', action='store_true', help='Replace duplicate with hardlink')
    #parser.add_argument('--move',  help='Move duplicates to specified directory')
    parser.add_argument('--from-file',  help='Provide a text file with sha1sums from an alternate location')
    parser.add_argument('--from-stdin',  help='Provide a text file with sha1sums from an alternate location')
    #parser.add_argument('--protect', action='store_true', help='Do not delete ANY file from first directory, even if duplicates exist')
    #parser.add_argument('--cache', action='store_true', help='Cache resulting SHA1 digests and use for subsequent invocations')
    parser.add_argument('--verbose', action='store_true', help='display verbose messages')
    args = parser.parse_args()

    # set verbose flag
    global VERBOSE
    VERBOSE = args.verbose if args.verbose else False
    
    if args.directories:
 
        # --from-file
        if args.from_file:
            # parse source file into multidict
            source_md = multidict()
            with open(args.from_file) as f:
                for line in f:
                    # maxsplit=1 in case there are spaces in the path
                    digest,path = line.split(' ', 1)
                    source_md[digest] = path.strip()
                
            # find files that are duplicates of those listed in source file
            md = find_duplicates_with_source(args.directories, source_md)

            # --delete 
            if args.delete:
                # detele all including the first because assumed that source files are stored elsewhere
                delete_duplicates(md, keep_first=False)
            
            # default
            else:
                print_duplicates(md)

        # find duplicates in local directories
        else:
            md = find_duplicates(args.directories)

            # --delete 
            if args.delete:
                delete_duplicates(md)

            # default
            else:
                print_duplicates(md)

    # argument error, print usage
    else:
        parser.print_usage()



